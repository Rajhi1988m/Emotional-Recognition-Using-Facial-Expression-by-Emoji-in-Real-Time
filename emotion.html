<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="content-type" content="text/html; charset=UTF-8">
            <!-- attach on the jquery -->
        <script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
            <!-- attach on the affectiva -->
        <script src="https://download.affectiva.com/js/3.2/affdex.js"></script>
            <!-- attach on the bootstrap and css file -->
        <link rel="stylesheet" href="css/bootstrap.min.css">
        <script src="js/bootstrap.min.js"></script>

    </head>
    <body>
           <!-- Organize the body and Bottoms -->
            <div style="width: 100%">
			<div style="margin: 0px auto;width: 300px;">
                    <div style="height:15em;">
                        <strong><center><h5>Beginning Tracking Emotions Using Facial Expression by Emoji</h5></center></strong>
                        <div id="results" style="word-wrap:break-word;"></div>
                    </div>
					<div id="affdex_elements" style="width:480;height:320px;"></div>
                    <div>
                         <center> <button class="btn btn-success" id="start" onclick="Record()">Record</button>
                <button class="btn btn-danger" id="stop" onclick="Stop()">Stop</button>
                             <button class="btn btn-warning" id="reset" onclick="Reset()">Reset</button> </center>
                    </div>
				
            </div>
			</div>
            <div>
              

                <script>
                    var TheDivRoot = $("#affdex_elements")[0];
                    var theWidth = 480; // The width is 480 
                    var theHeight = 320; // The Hight is 320
                    var theFaceMode = affdex.FaceDetectorMode.LARGE_FACES;
                    //Build a camera indicator and designate the image width/height and face emotion mode.
                    var sensation = new affdex.CameraDetector(TheDivRoot, theWidth, theHeight, theFaceMode);

                    // Authorise detection of each expression, classifiers, emotions, and emojis.
                    sensation.detectAllEmotions();
                    sensation.detectAllExpressions();
                    sensation.detectAllEmojis();
                    sensation.detectAllAppearance();

                    //Append a call-back to state when the emotion is initialized and available for running.
                    sensation.addEventListener("onInitializeSuccess", function () {
                        //Show canvas instead of video supplies because we want to draw the characteristic points on it
                        $("#face_video_canvas").css("display", "block");
                        $("#face_video").css("display", "none");
                    });

                    function log(node_name, msg) {
                        $(node_name).append("<span>" + msg + "</span><br />")
                    }

                    //This function is performed when the Record button is launched.
                    function Record() {
                        if (sensation && !sensation.isRunning) {
                            sensation.start();
                        }
                    }

                    // This function is performed when the Stop button is launched.
                    function Stop() {
                        if (sensation && sensation.isRunning) {
                            sensation.removeEventListener();
                            sensation.stop();
                        }
                    }
                    ;

                    //This function is performed when the Stop Reset is launched.
                    function Reset() {
                        if (sensation && sensation.isRunning) {
                            sensation.reset();

                            $('#results').html("");
                        }
                    };

                    //Append a call-back to state when camera access is not prevented
                    sensation.addEventListener("onWebcamConnectSuccess", function () {
                    });

                    //Append a call-back to state when camera is refused
                    sensation.addEventListener("onWebcamConnectFailure", function () {
                        alert("It cannot connect to webcam");
                    });

                    //Add a callback to notify when emotion is stopped
                    sensation.addEventListener("onStopSuccess", function () {
                        $("#results").html("");
                    });

                    //Add a callback to receive the results from processing an image.
                    //The faces object contains the list of the faces detected in an image.
                    //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
                    sensation.addEventListener("onImageResultsSuccess", function (faces, image, timestamp) {
                        $('#results').html("");
                        log('#results', "Timestamps is: " + timestamp.toFixed(2));
                        log('#results', "The Number of faces has found: " + faces.length);
                        if (faces.length > 0) {
                            var emoji = document.createElement("a");
                            emoji.style.fontSize = "100px";
                            emoji.innerHTML = faces[0].emojis.dominantEmoji;
                            $("#results").append(emoji);
                            drawFeaturePoints(image, faces[0].featurePoints);
                        }
                    });

                    //Draw the detected facial feature points on the image
                    function drawFeaturePoints(img, featurePoints) {
                        var contxt = $('#face_video_canvas')[0].getContext('2d');

                        var hRatio = contxt.canvas.width / img.width;
                        var vRatio = contxt.canvas.height / img.height;
                        var ratio = Math.min(hRatio, vRatio);

                        contxt.strokeStyle = "#FFFFFF";
                        for (var id in featurePoints) {
                            contxt.beginPath();
                            contxt.arc(featurePoints[id].x,
                                    featurePoints[id].y, 2, 0, 2 * Math.PI);
                            contxt.stroke();

                        }
                    }
                </script>
        </div>
    </body>
</html>